{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "\n",
    "# 参考：https://www.cnblogs.com/pinard/p/6136914.html调参\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "X, y = load_iris(return_X_y=True)\n",
    "# data = loadmat('data1.mat')\n",
    "# X = data['X']\n",
    "# y = data['y'].flatten()\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1,train_size=0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=GradientBoostingClassifier(learning_rate=1.0,\n",
       "                                                             max_depth=1,\n",
       "                                                             random_state=0),\n",
       "                   learning_rate=0.9, n_estimators=800)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当我们对Adaboost调参时，主要要对两部分内容进行调参，\n",
    "#           第一部分是对我们的Adaboost的框架进行调参， \n",
    "#          第二部分是对我们选择的弱分类器进行调参。两者相辅相成\n",
    "\n",
    "# 对于algorithm 参数有两个：SAMME和SAMME.R，（AdaBoostClassifier的默认算法algorithm的值也是SAMME.R，主要是迭代更快）\n",
    "\n",
    "\n",
    "# n_estimators,默认50，表示弱学习器的最大迭代次数，或者说最大的弱学习器的个数\n",
    "# 一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合\n",
    "\n",
    "# 主要调参是调n_estimators和learning_rate两个\n",
    "\n",
    "# 对于AdaBoostClassifier的弱学习器默认是CART分类树DecisionTreeClassifier，可以设置参数：\n",
    "\n",
    "# # 0.9613899613899614\n",
    "# clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, min_samples_split=20, min_samples_leaf=5),\n",
    "#                          algorithm=\"SAMME\",\n",
    "#                          n_estimators=500, learning_rate=0.8)\n",
    "\n",
    "\n",
    "# # 0.9845559845559846\n",
    "# clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5, min_samples_split=20, min_samples_leaf=7),\n",
    "#                          algorithm=\"SAMME.R\",\n",
    "#                          n_estimators=700, learning_rate=1)\n",
    "\n",
    "\n",
    "# base_estimator = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=5, min_samples_split=40, min_samples_leaf=9) # test_acc: 0.9845559845559846\n",
    "\n",
    "\n",
    "# # 看着https://scikit-learn.org/stable/search.html?q=Classifier网址的分类器选几个吧\n",
    "# base_estimator=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)# test_acc: 0.8918918918918919\n",
    "# base_estimator=GradientBoostingClassifier(max_depth=5, random_state=10)# 0.9845559845559846\n",
    "\n",
    "clf = AdaBoostClassifier(GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0),algorithm=\"SAMME\",n_estimators=800, learning_rate=0.9)\n",
    "\n",
    "# base_estimator = SVC(gamma='auto')# test_acc: 0.5791505791505791\n",
    "# # base_estimator = SGDClassifier(max_iter=1000, tol=1e-3)# test_acc: 0.5791505791505791\n",
    "# # base_estimator = ExtraTreeClassifier(random_state=0)# test_acc: 0.915057915057915\n",
    "# clf = AdaBoostClassifier(clf_tree,algorithm=\"SAMME\",n_estimators=200, learning_rate=1.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# clf = AdaBoostClassifier(n_estimators=80)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "acc = clf.score(X_test, y_test)\n",
    "print('test_acc:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predict(model,axes):\n",
    "    x0s = np.linspace(axes[0],axes[1],100)\n",
    "    x1s = np.linspace(axes[2],axes[3],100)\n",
    "    x0, x1 = np.meshgrid(x0s,x1s)\n",
    "    X = np.c_[x0.ravel(),x1.ravel()]\n",
    "    y_pred = model.predict(X).reshape(x0.shape)\n",
    "    y_decision = model.decision_function(X).reshape(x0.shape)\n",
    "    plt.contour(x0,x1,y_pred,cmap=plt.cm.winter)\n",
    "    plt.contour(x0,x1,y_decision,cmap=plt.cm.winter,alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集上可视化\n",
    "plt.scatter(X_train[:,0],X_train[:,1],c=y_train.flatten())\n",
    "# plot_predict(clf,[X_train[:,0].min(),X_train[:,0].max(),X_train[:,1].min(),X_train[:,0].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集上可视化\n",
    "plt.scatter(X_test[:,0],X_test[:,1],c=y_test.flatten())\n",
    "# plot_predict(clf,[X_test[:,0].min(),X_test[:,0].max(),X_test[:,1].min(),X_test[:,0].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
